/*****
*
* EMR Hands-on
*
*****/

/* ADD Library for Json parser */
ADD jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar;

/* Create table for input data */
CREATE EXTERNAL TABLE IF NOT EXISTS input_logs (
host STRING,
user STRING,
method STRING,
path STRING,
code STRING,
size INT,
referer STRING,
node STRING,
timestamp STRING,
version INT,
type STRING,
tags STRING,
geoip STRING
)
ROW FORMAT SERDE 'com.amazon.elasticmapreduce.JsonSerde'
with serdeproperties (
'paths'='host,user,method,path,code,size,referer,@node,@timestamp,@version,type,tags,geoip.country_code2'
)
LOCATION 's3://{data_input_bucket}/input/';

/*
* data_input_bucketの値
*
* Tokyo: awsbigdata-boot-camp-tokyo
* Oregon: awsbigdata-boot-camp-oregon
* Virginia: awsbigdata-boot-camp
*/


/*
*
* Create table for output data
* Please input your S3 bucket name into LOCATION section.
*
*/
CREATE EXTERNAL TABLE IF NOT EXISTS output_logs (
user STRING,
path STRING,
timestamp STRING,
geoip STRING
)
PARTITIONED BY (dt STRING)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n'
STORED AS TEXTFILE
LOCATION 's3://{input_your_bucket}/output/'

/* Set parameter for partition */
SET hive.exec.dynamic.partition=true;
SET hive.exec.dynamic.partition.mode=nonstrict;

/* Inser data from input table to output table */
INSERT OVERWRITE TABLE output_logs PARTITION(dt)
SELECT
user,
path,
timestamp,
geoip,
split(timestamp,'T')[0]
FROM input_logs
DISTRIBUTE BY split(timestamp,'T')[0];




/*****
*
* Redshift Hands-on
*
*****/

/* Create table for logs */
CREATE table logs (
user1 VARCHAR(10),
path VARCHAR(2048),
time VARCHAR(24),
geoip VARCHAR(2)
);

/*
*
* Copy data from S3 to Redshift table
* Please input your S3 bucket name into FROM section and CREDENTIALS into CREDENTIALS section.
*
*/
COPY logs from 's3://{input_your_bucket}/output/'
CREDENTIALS 'aws_access_key_id={input_your_access_key};aws_secret_access_key={input_your_secret_key}'
delimiter ','
CSV QUOTE '''';

